{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.__version__)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "#import keras\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, UpSampling2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization\n",
    "from keras.layers.merge import Add\n",
    "from keras.layers.core import Dropout\n",
    "#import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization\n",
    "from keras.layers.merge import Add\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "from keras.layers import Input, Activation, Add\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "image_shape = (448,896,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNET\n",
    "\n",
    "def res_block(x, nb_filters, strides):\n",
    "    res_path = BatchNormalization()(x)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same', strides=strides[0])(res_path)\n",
    "    res_path = BatchNormalization()(res_path)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', strides=strides[1])(res_path)\n",
    "\n",
    "    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1), strides=strides[0])(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    res_path = add([shortcut, res_path])\n",
    "    return res_path\n",
    "\n",
    "\n",
    "def encoder(x):\n",
    "    to_decoder = []\n",
    "\n",
    "    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    main_path = BatchNormalization()(main_path)\n",
    "    main_path = Activation(activation='relu')(main_path)\n",
    "\n",
    "    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n",
    "\n",
    "    shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1))(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    main_path = add([shortcut, main_path])\n",
    "    # first branching to decoder\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [128, 128], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    return to_decoder\n",
    "\n",
    "\n",
    "def decoder(x, from_encoder):\n",
    "    main_path = UpSampling2D(size=(2, 2))(x)\n",
    "    main_path = concatenate([main_path, from_encoder[2]], axis=3)\n",
    "    main_path = res_block(main_path, [256, 256], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = concatenate([main_path, from_encoder[1]], axis=3)\n",
    "    main_path = res_block(main_path, [128, 128], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = concatenate([main_path, from_encoder[0]], axis=3)\n",
    "    main_path = res_block(main_path, [64, 64], [(1, 1), (1, 1)])\n",
    "\n",
    "    return main_path\n",
    "\n",
    "\n",
    "def build_res_unet( ):\n",
    "    inputs = Input(shape=image_shape)\n",
    "\n",
    "    to_decoder = encoder(inputs)\n",
    "\n",
    "    path = res_block(to_decoder[2], [512, 512], [(2, 2), (1, 1)])\n",
    "\n",
    "    path = decoder(path, from_encoder=to_decoder)\n",
    "\n",
    "    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path)\n",
    "\n",
    "    return Model(input=inputs, output=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from keras.layers import ReflectionPadding2D, res_block\n",
    "\n",
    "ngf = 64\n",
    "input_nc = 1\n",
    "output_nc = 1\n",
    "input_shape_generator = (448, 896, input_nc)\n",
    "n_blocks_gen = 9\n",
    "\n",
    "\n",
    "def generator_model():\n",
    "    \"\"\"Build generator architecture.\"\"\"\n",
    "    # Current version : ResNet block\n",
    "    inputs = Input(shape=image_shape)\n",
    "\n",
    "    x = ReflectionPadding2D((3, 3))(inputs)\n",
    "    x = Conv2D(filters=ngf, kernel_size=(7,7), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Increase filter number\n",
    "    n_downsampling = 2\n",
    "    for i in range(n_downsampling):\n",
    "        mult = 2**i\n",
    "        x = Conv2D(filters=ngf*mult*2, kernel_size=(3,3), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    # Apply 9 ResNet blocks\n",
    "    mult = 2**n_downsampling\n",
    "    for i in range(n_blocks_gen):\n",
    "        x = res_block(x, ngf*mult, use_dropout=True)\n",
    "\n",
    "    # Decrease filter number to 3 (RGB)\n",
    "    for i in range(n_downsampling):\n",
    "        mult = 2**(n_downsampling - i)\n",
    "        x = Conv2DTranspose(filters=int(ngf * mult / 2), kernel_size=(3,3), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    x = ReflectionPadding2D((3,3))(x)\n",
    "    x = Conv2D(filters=output_nc, kernel_size=(7,7), padding='valid')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    # Add direct connection from input to output and recenter to [-1, 1]\n",
    "    outputs = Add()([x, inputs])\n",
    "    outputs = Lambda(lambda z: z/2)(outputs)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ndf = 64\n",
    "output_nc = 1\n",
    "input_shape_discriminator = (448, 896, output_nc)\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    \"\"\"Build discriminator architecture.\"\"\"\n",
    "    n_layers, use_sigmoid = 3, False\n",
    "    inputs = Input(shape=input_shape_discriminator)\n",
    "\n",
    "    x = Conv2D(filters=ndf, kernel_size=(4,4), strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult, nf_mult_prev = 1, 1\n",
    "    for n in range(n_layers):\n",
    "        nf_mult_prev, nf_mult = nf_mult, min(2**n, 8)\n",
    "        x = Conv2D(filters=ndf*nf_mult, kernel_size=(4,4), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult_prev, nf_mult = nf_mult, min(2**n_layers, 8)\n",
    "    x = Conv2D(filters=ndf*nf_mult, kernel_size=(4,4), strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(filters=1, kernel_size=(4,4), strides=1, padding='same')(x)\n",
    "    if use_sigmoid:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='tanh')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x, name='Discriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "def generator_containing_discriminator_multiple_outputs(generator, discriminator):\n",
    "    inputs = Input(shape=image_shape)\n",
    "    generated_images = generator(inputs)\n",
    "    outputs = discriminator(generated_images)\n",
    "    model = Model(inputs=inputs, outputs=[generated_images, outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from  keras.layers import Concatenate\n",
    "\n",
    "\n",
    "image_shape = (448,896,1)\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    vgg = VGG16(include_top=False,   input_shape=(512,896,3) )\n",
    "    y_true_c =   Concatenate()([y_true,y_true,y_true])    \n",
    "    y_pred_c =   Concatenate()([y_pred,y_pred,y_pred])    \n",
    "\n",
    "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "    loss_model.trainable = False\n",
    "    return K.mean(K.square(loss_model(y_true_c) - loss_model(y_pred_c)))\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing images ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9cf22043294ee78c6148717697666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupali/anaconda3/lib/python3.6/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "im_width = 896\n",
    "im_height = 448\n",
    "border = 5\n",
    "path_train = 'train/'\n",
    "path_test = 'test/'\n",
    "\n",
    "def get_data(path, train=True):\n",
    "    ids = next(os.walk(path + \"raw\"))[2]\n",
    "    \n",
    "    X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "    if train:\n",
    "        y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "        # Load raw\n",
    "        img = load_img(path + 'raw/' + id_, grayscale=True)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (448,896, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "        # Load average\n",
    "        if train:\n",
    "            average = img_to_array(load_img(path + 'average/' + id_, grayscale=True))\n",
    "            average = resize(average, (448, 896, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "        # Save images\n",
    "        X[n, ..., 0] = x_img.squeeze() / 255\n",
    "        if train:\n",
    "            y[n] = average / 255\n",
    "    print('Done!')\n",
    "    if train:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "    \n",
    "x_test, y_test = get_data(path_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupali/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/home/rupali/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/home/rupali/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.004141562240196\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import click\n",
    "import scipy.misc\n",
    "#from scipy.stats import signaltonoise\n",
    "p=[]\n",
    "def test(batch_size):\n",
    "    #g = generator_model()\n",
    "    g =build_res_unet()\n",
    "\n",
    "    g.load_weights('GAN/410/generator_24_86.h5')\n",
    "    generated_images = g.predict(x=x_test, batch_size=batch_size)\n",
    "    #generated = np.array([deprocess_image(img) for img in generated_images])\n",
    "    #x_test = deprocess_image(x_test)\n",
    "    #y_test = deprocess_image(y_test)\n",
    "   \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        y = y_test[i, :, :, :]\n",
    "        x = x_test[i, :, :, :]\n",
    "        img = generated_images[i, :, :, :]\n",
    "        output = np.concatenate((y, x, img), axis=1)\n",
    "        scipy.misc.imsave('GAN/SBSDI_results/results{}.png'.format(i+1),img[:,:,0])\n",
    "        scipy.misc.imsave('GAN/SBSDI_results/raw{}.png'.format(i+1),x[:,:,0])\n",
    "        scipy.misc.imsave('GAN/SBSDI_results/average{}.png'.format(i+1),y[:,:,0])\n",
    "\n",
    "        p.append(compare_psnr(img[:,:,0],y[:,:,0]))\n",
    "        #snr = signaltonoise(img[:,:,0])\n",
    "        #print(p)\n",
    "    print(np.array(p).mean())\n",
    " \n",
    "\n",
    "        #im = Image.fromarray(output.astype(np.uint8))\n",
    "        #im.save('results{}.png'.format(i))\n",
    "\n",
    "test(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.270462589881618, 23.755853416680534, 23.067726741157337, 27.53470119858962, 32.19994124182078, 26.024050720067045, 22.309713476835324, 22.549416221351976, 21.439642824429257, 32.501234359969274, 27.691091340632347, 27.749814430998274, 24.540039674665394, 26.754397352407615, 28.017482773832324, 26.53797653271586, 27.671309043976052, 25.7199477922957]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
